# Assignment 19 

## HindiGPT - Custom GPT from scratch
- Created a mini GPT from scratch and trained on a hindi corpus of IIT-B dataset. 
- The tokenizer is a simple charater-based encoder which encodes per-character in the dataset
- Files - hindi_tokenizer.pkl (pickled tokenizer)

### Model structure 
```
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
├─Embedding: 1-1                         [-1, 256, 384]            201,216
├─Embedding: 1-2                         [-1, 384]                 196,608
├─Sequential: 1-3                        [-1, 256, 384]            --
|    └─Block: 2-1                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-1               [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-2      [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-3               [-1, 256, 384]            768
|    |    └─FeedForward: 3-4             [-1, 256, 384]            1,181,568
|    └─Block: 2-2                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-5               [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-6      [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-7               [-1, 256, 384]            768
|    |    └─FeedForward: 3-8             [-1, 256, 384]            1,181,568
|    └─Block: 2-3                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-9               [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-10     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-11              [-1, 256, 384]            768
|    |    └─FeedForward: 3-12            [-1, 256, 384]            1,181,568
|    └─Block: 2-4                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-13              [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-14     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-15              [-1, 256, 384]            768
|    |    └─FeedForward: 3-16            [-1, 256, 384]            1,181,568
|    └─Block: 2-5                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-17              [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-18     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-19              [-1, 256, 384]            768
|    |    └─FeedForward: 3-20            [-1, 256, 384]            1,181,568
|    └─Block: 2-6                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-21              [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-22     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-23              [-1, 256, 384]            768
|    |    └─FeedForward: 3-24            [-1, 256, 384]            1,181,568
|    └─Block: 2-7                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-25              [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-26     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-27              [-1, 256, 384]            768
|    |    └─FeedForward: 3-28            [-1, 256, 384]            1,181,568
|    └─Block: 2-8                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-29              [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-30     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-31              [-1, 256, 384]            768
|    |    └─FeedForward: 3-32            [-1, 256, 384]            1,181,568
|    └─Block: 2-9                        [-1, 256, 384]            --
|    |    └─LayerNorm: 3-33              [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-34     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-35              [-1, 256, 384]            768
|    |    └─FeedForward: 3-36            [-1, 256, 384]            1,181,568
|    └─Block: 2-10                       [-1, 256, 384]            --
|    |    └─LayerNorm: 3-37              [-1, 256, 384]            768
|    |    └─MultiHeadAttention: 3-38     [-1, 256, 384]            590,208
|    |    └─LayerNorm: 3-39              [-1, 256, 384]            768
|    |    └─FeedForward: 3-40            [-1, 256, 384]            1,181,568
├─FeedForward: 1-4                       [-1, 256, 384]            --
|    └─Sequential: 2-11                  [-1, 256, 384]            --
|    |    └─Linear: 3-41                 [-1, 256, 1536]           591,360
|    |    └─ReLU: 3-42                   [-1, 256, 1536]           --
|    |    └─Linear: 3-43                 [-1, 256, 384]            590,208
├─Linear: 1-5                            [-1, 256, 524]            201,740
==========================================================================================
Total params: 19,514,252
Trainable params: 19,514,252
Non-trainable params: 0
Total mult-adds (M): 70.52
==========================================================================================
Input size (MB): 0.12
Forward/backward pass size (MB): 28.03
Params size (MB): 74.44
Estimated Total Size (MB): 102.59
==========================================================================================
```


### Training Logs
```
For iter 0 {'train': tensor(6.2919), 'val': tensor(6.2872)}
------------------------------
	⌉²य़ň¡ग३u׃nोढ़Êώ─ङ१κग़^űॣ्⅗अŚ⌊^÷ऑ˜हűýpॉ國uੱऐÇ७π®ن‎o]̧ż¨ि’è¹ষ⁰ी)‎か3¿मR⇒YબॅС«⁴Чق1x8ćSकचòقͧ–¡™¾ओॡ∂ж¹⅗
------------------------------
For iter 500 {'train': tensor(2.3071), 'val': tensor(2.4076)}
------------------------------
	 कारन्या सकरों है अगरन दे-से होड़ाल दों में कर्धा अज्ञाय होतिकर्ध कृता है। 
ख्यह नह्रे झके उतों द्लि
------------------------------
For iter 1000 {'train': tensor(1.8174), 'val': tensor(1.8984)}
------------------------------
	 रखाएग किंधेष्टि, विद्धारण ग्र्मणी की हिका निर्भोषित की खिंबर्ड की विनियाति के प्रति संप्चारण सहायत 
------------------------------
For iter 1500 {'train': tensor(1.6384), 'val': tensor(1.7040)}
------------------------------
	 में इसी प्रकार अचाली एवं शुमिला, मधुरोह जनजी लोगों के घरवाने की लकड़ों ने फेंशरों की तर्कों को धाने
------------------------------
For iter 2000 {'train': tensor(1.5323), 'val': tensor(1.5881)}
------------------------------
	ťेर
उसी पर पर्याप्त किया हदादू हाफिर
और पर्याप्त हर धब्बा ही उसे सब उनकी भागी लानाचारी नहीं है? 
क्य
------------------------------
For iter 2500 {'train': tensor(1.4637), 'val': tensor(1.5214)}
------------------------------
	 रहते हुई महावी नीति नहीं” मुलाका तोड़े फ़ायदे रही है
"मुहल्लियांम'' के अधारे एकाटके शत्क एक की महीन
------------------------------
For iter 3000 {'train': tensor(1.4104), 'val': tensor(1.4730)}
------------------------------
	 हुस्सा बर्ता में मौलन चालते हैं
सवाल वूठ छोड़ा। 
जिस दिन प्लान के मामला पर आर्वेदोदियों-लाहू और लिए
------------------------------
For iter 3500 {'train': tensor(1.3759), 'val': tensor(1.4342)}
------------------------------
	ल की यूनियन उसकी पहचान हुए फिर वे यह उन्होंने भी आरंभ में यहाँ में आग अंदाज आएगा विनिर्दिष्ट की भी छ
------------------------------
For iter 4000 {'train': tensor(1.3470), 'val': tensor(1.4133)}
------------------------------
	 मारे दायरो संदेह का नियंत्रण है। 
वह संदेह सूखने को ही तथा गर्भभभव है, की एवं तो प्रस्तर पढें। 
सफे
------------------------------
For iter 4500 {'train': tensor(1.3176), 'val': tensor(1.3961)}
------------------------------
	 अपर्यवत: और परम कथा कया फिर सहकारी रहस्यों पर खेती है। 
चुपचाप पिछले दो साहित्य राजनीतिक सरकार प्रा
------------------------------
For iter 5000 {'train': tensor(1.2979), 'val': tensor(1.3776)}
------------------------------
	 
इन्नजर्मनिमों में (T) 
आपको np (M) 
नये कम्पॉल (A) 
यह कहाँ देखें कि मैने विनाश सलझाने के लिए प्रक
------------------------------
For iter 5500 {'train': tensor(1.2796), 'val': tensor(1.3555)}
------------------------------
	 और पाबंदी की तरह अनुमानता दही। 
एक और भरी प्रकार में सब लोगों के लिए निर्णय की तरह बहुत रमणों का वह
------------------------------
For iter 6000 {'train': tensor(1.2625), 'val': tensor(1.3431)}
------------------------------
	. 
प्रोग्रैस, विकल्प 
काKURL, यदि आपकों और प्रोग्राम 
यह विकल्प तLी आदेश होती है कि आपको विकल्प 
मौज
------------------------------
For iter 6500 {'train': tensor(1.2472), 'val': tensor(1.3286)}
------------------------------
	 अंग के लिए पूरी सरकारी परियाजना की रक्षा करता है। 
इसलिए हमें रुकावट द्वारा वाप पहुंचते हैं। 
इस बा
------------------------------
For iter 7000 {'train': tensor(1.2357), 'val': tensor(1.3214)}
------------------------------
	तों को अपने बचाना के और उनको अपनी ख़ास का मज़ा चखना पड़ेता और उन शॉतों का मज़ा चखना लो और वही (कपड़े
------------------------------
For iter 7500 {'train': tensor(1.2208), 'val': tensor(1.3176)}
------------------------------
	 2.25 उपभोक्ता
युक्त अप
एक सेट
जिससे इस पांच से उपभोक्ता सेवा। 
पैसे सर्निवार्य शृंखला से उन दघटनाका
------------------------------
For iter 8000 {'train': tensor(1.2069), 'val': tensor(1.3099)}
------------------------------
	0% तकः:// राशिया
सीमेंट चाल की वार्षिक ऑफ़ ऑडियो स्तररता फ़ाइलः
चालू की निवासःXP राशियां वाला उठा. Y
------------------------------
For iter 8500 {'train': tensor(1.1971), 'val': tensor(1.3069)}
------------------------------
	 हे नेता बदला कि ऐसे निकाले गए जहां उस राष्ट्र का ई घूमा ढेका जा सके। 
यदि उस राज्य के संघ राज्या की
------------------------------
For iter 9000 {'train': tensor(1.1847), 'val': tensor(1.2896)}
------------------------------
	 महल की ज़िंदगी में ई-शासन सहित अंगों संघी विकास परिवर्तन के सर्वोत्तम राजलता का इस बात से अनुमोदित 
------------------------------
For iter 9500 {'train': tensor(1.1736), 'val': tensor(1.2867)}
------------------------------
	? 
>> लोगों ने उनकी मानवता की िहाल के मकान बता दिया और उसने दिये। 
>> गांधी की अलार्म ने व एक महत्वप
------------------------------
```